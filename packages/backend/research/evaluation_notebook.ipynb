{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_methods import EvaluationMethods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_methods = EvaluationMethods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does the ELO Rating System work in the context of prompt testing and ranking?: 1603.1750940569336\n",
      "Name the key services provided by PromptlyTech.: 1578.23677654491\n",
      "What are some innovative approaches suggested for prompt evaluation in Task 5?: 1557.5513009271729\n",
      "How does the user interface contribute to the overall prompt engineering system in Task 5?: 1527.3662108276217\n",
      "Explain the importance of Automatic Evaluation Data Generation in PromptlyTech's offerings.: 1522.186527381688\n",
      "What is the primary business objective of PromptlyTech?: 1482.6702292645643\n"
     ]
    }
   ],
   "source": [
    "# Define prompts and initial ratings\n",
    "prompts = [\n",
    "    \"What is the primary business objective of PromptlyTech?\",\n",
    "    \"Name the key services provided by PromptlyTech.\",\n",
    "    \"Explain the importance of Automatic Evaluation Data Generation in PromptlyTech's offerings.\",\n",
    "    \"How does the ELO Rating System work in the context of prompt testing and ranking?\",\n",
    "    \"What are some innovative approaches suggested for prompt evaluation in Task 5?\",\n",
    "    \"How does the user interface contribute to the overall prompt engineering system in Task 5?\"\n",
    "]\n",
    "elo_ratings = {prompt: 1500 for prompt in prompts}  # Initial ratings\n",
    "\n",
    "# Conduct multiple rounds of evaluation\n",
    "for _ in range(10):  # Number of rounds\n",
    "    elo_ratings = eval_methods.elo_ratings_func(prompts, elo_ratings)\n",
    "\n",
    "# Sort prompts by their final Elo ratings\n",
    "sorted_prompts = sorted(prompts, key=lambda x: elo_ratings[x], reverse=True)\n",
    "\n",
    "# Print the ranked prompts\n",
    "for prompt in sorted_prompts:\n",
    "    print(f\"{prompt}: {elo_ratings[prompt]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts evaluation\n",
    "1. **How does the user interface contribute to the overall prompt engineering system in Task 5?:** 1557.24\n",
    "   - This prompt has a **high rating**, suggesting it was evaluated as very relevant and valuable to understanding the contribution of the user interface to the prompt engineering system in Task 5.\n",
    "\n",
    "2. **What are some innovative approaches suggested for prompt evaluation in Task 5?:** 1543.87\n",
    "   - This prompt also received a **high rating**, indicating that it was considered valuable in exploring innovative approaches for prompt evaluation in Task 5.\n",
    "\n",
    "3. **What is the primary business objective of PromptlyTech?:** 1528.40\n",
    "   - The prompt received a **solid rating**, indicating it was perceived as relevant and important in understanding the primary business objective of PromptlyTech.\n",
    "\n",
    "4. **How does the ELO Rating System work in the context of prompt testing and ranking?:** 1511.07\n",
    "   - This prompt has a **good rating**, suggesting it was seen as valuable in explaining the functioning of the ELO Rating System in the context of prompt testing and ranking.\n",
    "\n",
    "5. **Name the key services provided by PromptlyTech.:** 1508.48\n",
    "   - The prompt received a **reasonable rating**, indicating it was considered important in identifying the key services provided by PromptlyTech.\n",
    "\n",
    "6. **Explain the importance of Automatic Evaluation Data Generation in PromptlyTech's offerings.:** 1497.73\n",
    "   - This prompt received a **slightly lower rating**, suggesting it may be perceived as less critical compared to other prompts in understanding the importance of Automatic Evaluation Data Generation in PromptlyTech's offerings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prompt(main_prompt, test_cases):\n",
    "    evaluations = {}\n",
    "\n",
    "    # Evaluate the main prompt using Monte Carlo and Elo methods\n",
    "    evaluations['main_prompt'] = {\n",
    "        'Monte Carlo Evaluation': eval_methods.monte_carlo_eval(main_prompt),\n",
    "        'Elo Rating Evaluation': eval_methods.elo_eval(main_prompt)\n",
    "    }\n",
    "\n",
    "    # Evaluate each test case\n",
    "    for idx, test_case in enumerate(test_cases):\n",
    "        evaluations[f'test_case_{idx+1}'] = {\n",
    "            'Monte Carlo Evaluation': eval_methods.monte_carlo_eval(test_case),\n",
    "            'Elo Rating Evaluation': eval_methods.elo_eval(test_case)\n",
    "        }\n",
    "\n",
    "    return evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main_prompt': {'Monte Carlo Evaluation': 1.93, 'Elo Rating Evaluation': 1519.2019499940866}, 'test_case_1': {'Monte Carlo Evaluation': 2.01, 'Elo Rating Evaluation': 1519.2019499940866}, 'test_case_2': {'Monte Carlo Evaluation': 2.05, 'Elo Rating Evaluation': 1489.2019499940866}, 'test_case_3': {'Monte Carlo Evaluation': 2.01, 'Elo Rating Evaluation': 1519.2019499940866}, 'test_case_4': {'Monte Carlo Evaluation': 2.04, 'Elo Rating Evaluation': 1504.2019499940866}, 'test_case_5': {'Monte Carlo Evaluation': 2.01, 'Elo Rating Evaluation': 1519.2019499940866}, 'test_case_6': {'Monte Carlo Evaluation': 1.92, 'Elo Rating Evaluation': 1519.2019499940866}}\n"
     ]
    }
   ],
   "source": [
    "main_prompt = \"How does effective prompt engineering contribute to the success of AI-driven solutions, especially in optimizing the use of Language Models (LLMs) in various industries?\"\n",
    "test_cases = [\n",
    "    \"What role does prompt engineering play in enhancing decision-making, operational efficiency, and customer experience in various industries?\",\n",
    "    \"How does Automatic Prompt Generation by PromptlyTech streamline the process of creating effective prompts for businesses?\",\n",
    "    \"In what ways does Automatic Evaluation Data Generation by PromptlyTech contribute to enhancing the reliability and performance of LLM applications?\",\n",
    "    \"Explain the significance of PromptlyTech's Prompt Testing and Ranking Service in ensuring accurate and contextually relevant responses from chatbots and virtual assistants.\",\n",
    "    \"Can you elaborate on the innovative approaches mentioned for prompt evaluation in Task 5 of the challenge?\",\n",
    "    \"How does the user interface developed for prompt engineering contribute to the overall user experience in Task 5?\"\n",
    "]\n",
    "result = evaluate_prompt(main_prompt, test_cases)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "#### 1. Monte Carlo Evaluation:\n",
    "   - **Scores Range:** From 1 to 3, with higher scores indicating greater relevance or quality of the prompt.\n",
    "   ###### Interpretation:\n",
    "   - **1.9 (Main Prompt):** Slightly below average relevance or quality.\n",
    "   - **1.97, 1.98, 2.02, 2.04, 2.07 (Test Cases):** Scores around 2 suggest moderate relevance or quality. The variation indicates some test cases are deemed slightly more relevant or higher quality than others.\n",
    "\n",
    "#### 2. Elo Rating Evaluation:\n",
    "   - **Base Rating:** Usually starts at 1500, with changes based on the 'performance' of the prompt against a set of standards.\n",
    "   - **Higher than 1500:** Indicates the prompt performed better than average.\n",
    "   - **Lower than 1500:** Indicates the prompt performed worse than average.\n",
    "   ###### Interpretation:\n",
    "   - **1504.20 (Main Prompt):** Slightly below the average performance.\n",
    "   - **1489.20 (Test Cases 1, 2, 4, 5):** These prompts are rated above the average, suggesting better performance.\n",
    "   - **1504.20 (Test Case 3):** Slightly above average performance.\n",
    "\n",
    "#### Overall Interpretation:\n",
    "   - **Main Prompt:** Both evaluations suggest that the main prompt is slightly below average in terms of relevance and quality.\n",
    "   - **Test Cases:** Generally, the test cases are rated as average or slightly above average in both relevance and quality. Test Cases 1, 2, 4, and 5 seem to perform particularly well in the Elo evaluation, indicating they might be more effective or well-structured prompts compared to the main prompt and Test Case 3.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter  \n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Weaviate\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Weaviate\n",
    "import weaviate\n",
    "import os\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "# \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "def data_loader(file_path= '../prompts/context.txt'):\n",
    "    loader = TextLoader(file_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Chunk the data\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=15773, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retriever(chunks):\n",
    "    load_dotenv(find_dotenv())\n",
    "    \n",
    "\n",
    "    # # Setup vector database\n",
    "    client = weaviate.Client(\n",
    "    embedded_options = EmbeddedOptions()\n",
    "    )\n",
    "    \n",
    "    # Populate vector database\n",
    "    vectorstore = Weaviate.from_documents(\n",
    "      client = client,    \n",
    "      documents = chunks,\n",
    "      embedding = OpenAIEmbeddings(),\n",
    "      by_text = False\n",
    "    )\n",
    "    \n",
    "    # Define vectorstore as retriever to enable semantic search\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /Users/azizamed/.cache/weaviate-embedded: process ID 6729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-01-20T11:10:29+03:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-01-20T11:10:29+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-01-20T11:10:29+03:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50060\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"read_disk_use\",\"level\":\"warning\",\"msg\":\"disk usage currently at 91.87%, threshold set to 80.00%\",\"path\":\"/Users/azizamed/.local/share/weaviate\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_5386f93609844d2283e576a24c8e5a7b_AzD0hzqsPZoB in 17.733978ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_5386f93609844d2283e576a24c8e5a7b\",\"index\":\"langchain_5386f93609844d2283e576a24c8e5a7b\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_5386f93609844d2283e576a24c8e5a7b/AzD0hzqsPZoB/lsm\",\"shard\":\"AzD0hzqsPZoB\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":876904}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_bb4d98ea2fe84e1998373df882807506_rjL6yJUQEV3j in 4.344846ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_bb4d98ea2fe84e1998373df882807506\",\"index\":\"langchain_bb4d98ea2fe84e1998373df882807506\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_bb4d98ea2fe84e1998373df882807506/rjL6yJUQEV3j/lsm\",\"shard\":\"rjL6yJUQEV3j\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":136050}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_2d1c5d2910d5450a93acd491189fe01a_hc9jdgKn88pf in 4.466772ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_2d1c5d2910d5450a93acd491189fe01a\",\"index\":\"langchain_2d1c5d2910d5450a93acd491189fe01a\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_2d1c5d2910d5450a93acd491189fe01a/hc9jdgKn88pf/lsm\",\"shard\":\"hc9jdgKn88pf\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":165976}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_361d7bd500a746eb9326b8c2c116d088_gyJH0P1pTUrf in 3.161034ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_361d7bd500a746eb9326b8c2c116d088\",\"index\":\"langchain_361d7bd500a746eb9326b8c2c116d088\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_361d7bd500a746eb9326b8c2c116d088/gyJH0P1pTUrf/lsm\",\"shard\":\"gyJH0P1pTUrf\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":106026}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_8926263446bf4bb497bea99f0143898c_7bSQWRHhp7a5 in 3.473651ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_8926263446bf4bb497bea99f0143898c\",\"index\":\"langchain_8926263446bf4bb497bea99f0143898c\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_8926263446bf4bb497bea99f0143898c/7bSQWRHhp7a5/lsm\",\"shard\":\"7bSQWRHhp7a5\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":179034}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_bd94deabf3fd450493a14695b0293bc8_MgthMbooTVoq in 2.822082ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_bd94deabf3fd450493a14695b0293bc8\",\"index\":\"langchain_bd94deabf3fd450493a14695b0293bc8\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_bd94deabf3fd450493a14695b0293bc8/MgthMbooTVoq/lsm\",\"shard\":\"MgthMbooTVoq\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":87363}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_17bbdaa4279c488db6082b6609d17e65_Wo3w0e0EQ5AM in 2.593194ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_17bbdaa4279c488db6082b6609d17e65\",\"index\":\"langchain_17bbdaa4279c488db6082b6609d17e65\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_17bbdaa4279c488db6082b6609d17e65/Wo3w0e0EQ5AM/lsm\",\"shard\":\"Wo3w0e0EQ5AM\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":93540}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_619c6b40837e43d784a7afe3ddf243d2_glTRueqVIBtl in 7.567627ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_619c6b40837e43d784a7afe3ddf243d2\",\"index\":\"langchain_619c6b40837e43d784a7afe3ddf243d2\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_619c6b40837e43d784a7afe3ddf243d2/glTRueqVIBtl/lsm\",\"shard\":\"glTRueqVIBtl\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":322463}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_cb2de5f56ff34928914697985b690b2f_SZkahJx09wL2 in 3.312454ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_cb2de5f56ff34928914697985b690b2f\",\"index\":\"langchain_cb2de5f56ff34928914697985b690b2f\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_cb2de5f56ff34928914697985b690b2f/SZkahJx09wL2/lsm\",\"shard\":\"SZkahJx09wL2\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":105977}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_42d8c525334d4bf2aea0cd6fc8258e95_xvoxSUdvesEz in 2.218942ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_42d8c525334d4bf2aea0cd6fc8258e95\",\"index\":\"langchain_42d8c525334d4bf2aea0cd6fc8258e95\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_42d8c525334d4bf2aea0cd6fc8258e95/xvoxSUdvesEz/lsm\",\"shard\":\"xvoxSUdvesEz\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":76382}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_97b8f81b7d0b4287ac653954803ac4b4_ruzjwI6fKcs6 in 6.43721ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_97b8f81b7d0b4287ac653954803ac4b4\",\"index\":\"langchain_97b8f81b7d0b4287ac653954803ac4b4\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_97b8f81b7d0b4287ac653954803ac4b4/ruzjwI6fKcs6/lsm\",\"shard\":\"ruzjwI6fKcs6\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":118774}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_8f01034c5795444e8326261f233c75a0_UXELe1HZ38kN in 2.051924ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_8f01034c5795444e8326261f233c75a0\",\"index\":\"langchain_8f01034c5795444e8326261f233c75a0\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_8f01034c5795444e8326261f233c75a0/UXELe1HZ38kN/lsm\",\"shard\":\"UXELe1HZ38kN\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":81159}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_1e74abab74854b28bdbef6dd5bb3a491_qucOT7m1iTzi in 2.172835ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_1e74abab74854b28bdbef6dd5bb3a491\",\"index\":\"langchain_1e74abab74854b28bdbef6dd5bb3a491\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_1e74abab74854b28bdbef6dd5bb3a491/qucOT7m1iTzi/lsm\",\"shard\":\"qucOT7m1iTzi\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":92733}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_6c31f46e683c4955840a133107b0e8e2_ZWI1NxXy3WNV in 2.642758ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_6c31f46e683c4955840a133107b0e8e2\",\"index\":\"langchain_6c31f46e683c4955840a133107b0e8e2\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_6c31f46e683c4955840a133107b0e8e2/ZWI1NxXy3WNV/lsm\",\"shard\":\"ZWI1NxXy3WNV\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":92423}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_997b1ef680d84ceda00bfefd756e5388_HiEeu5lRDbOD in 2.595909ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_997b1ef680d84ceda00bfefd756e5388\",\"index\":\"langchain_997b1ef680d84ceda00bfefd756e5388\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_997b1ef680d84ceda00bfefd756e5388/HiEeu5lRDbOD/lsm\",\"shard\":\"HiEeu5lRDbOD\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":76878}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_e1486990586f4d289c1470a18ff5e6b3_Yt7xAr5nwqCp in 1.991136ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_e1486990586f4d289c1470a18ff5e6b3\",\"index\":\"langchain_e1486990586f4d289c1470a18ff5e6b3\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_e1486990586f4d289c1470a18ff5e6b3/Yt7xAr5nwqCp/lsm\",\"shard\":\"Yt7xAr5nwqCp\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":79336}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_274b8b31463e45ccb35ca23ebd3123b5_AQSjQDG1uhmh in 2.109385ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_274b8b31463e45ccb35ca23ebd3123b5\",\"index\":\"langchain_274b8b31463e45ccb35ca23ebd3123b5\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_274b8b31463e45ccb35ca23ebd3123b5/AQSjQDG1uhmh/lsm\",\"shard\":\"AQSjQDG1uhmh\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":79363}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_2d9294fc0e3448088208bbe039352c90_Oq2zV98SIhsP in 2.122711ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_2d9294fc0e3448088208bbe039352c90\",\"index\":\"langchain_2d9294fc0e3448088208bbe039352c90\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_2d9294fc0e3448088208bbe039352c90/Oq2zV98SIhsP/lsm\",\"shard\":\"Oq2zV98SIhsP\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":73823}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_19fc547c894944deb61033ce03a35df0_wITsEGidABEF in 2.043824ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_19fc547c894944deb61033ce03a35df0\",\"index\":\"langchain_19fc547c894944deb61033ce03a35df0\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_19fc547c894944deb61033ce03a35df0/wITsEGidABEF/lsm\",\"shard\":\"wITsEGidABEF\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":85796}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_3c5eaa7ac2e64aa78088115afe2d764f_BI04w1Ja6MAn in 2.227095ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_3c5eaa7ac2e64aa78088115afe2d764f\",\"index\":\"langchain_3c5eaa7ac2e64aa78088115afe2d764f\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_3c5eaa7ac2e64aa78088115afe2d764f/BI04w1Ja6MAn/lsm\",\"shard\":\"BI04w1Ja6MAn\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":73533}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_935cdfe45e284653b871388827ef0f15_O3WKFcwdhXyu in 2.424983ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_935cdfe45e284653b871388827ef0f15\",\"index\":\"langchain_935cdfe45e284653b871388827ef0f15\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_935cdfe45e284653b871388827ef0f15/O3WKFcwdhXyu/lsm\",\"shard\":\"O3WKFcwdhXyu\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":94820}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a4d3bb5037f74c1cbb5ddbda4a30ad63_dfBgdkLswFYI in 2.776019ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_a4d3bb5037f74c1cbb5ddbda4a30ad63\",\"index\":\"langchain_a4d3bb5037f74c1cbb5ddbda4a30ad63\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_a4d3bb5037f74c1cbb5ddbda4a30ad63/dfBgdkLswFYI/lsm\",\"shard\":\"dfBgdkLswFYI\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":75797}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_0841ccc6e48b4569943d2dd8f0900380_fOhxAQ0mA7xl in 1.915973ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_0841ccc6e48b4569943d2dd8f0900380\",\"index\":\"langchain_0841ccc6e48b4569943d2dd8f0900380\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_0841ccc6e48b4569943d2dd8f0900380/fOhxAQ0mA7xl/lsm\",\"shard\":\"fOhxAQ0mA7xl\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":82547}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_0d1ba446dc7846f8aa0a4f4ce559cea8_zUe5iWIHIrjS in 2.021959ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_0d1ba446dc7846f8aa0a4f4ce559cea8\",\"index\":\"langchain_0d1ba446dc7846f8aa0a4f4ce559cea8\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_0d1ba446dc7846f8aa0a4f4ce559cea8/zUe5iWIHIrjS/lsm\",\"shard\":\"zUe5iWIHIrjS\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":86924}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_8b7f53af715c4077a301c669c0ce2638_8lY0UT0vEcSf in 3.092474ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_8b7f53af715c4077a301c669c0ce2638\",\"index\":\"langchain_8b7f53af715c4077a301c669c0ce2638\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_8b7f53af715c4077a301c669c0ce2638/8lY0UT0vEcSf/lsm\",\"shard\":\"8lY0UT0vEcSf\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":109457}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_caab8639092a4993a3f5812d0527f236_EKYHpwF3ViXn in 3.422019ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_caab8639092a4993a3f5812d0527f236\",\"index\":\"langchain_caab8639092a4993a3f5812d0527f236\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_caab8639092a4993a3f5812d0527f236/EKYHpwF3ViXn/lsm\",\"shard\":\"EKYHpwF3ViXn\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":103610}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_254b43779e744f9886521bc56fe591f6_0iY927OAD4uU in 3.179246ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_254b43779e744f9886521bc56fe591f6\",\"index\":\"langchain_254b43779e744f9886521bc56fe591f6\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_254b43779e744f9886521bc56fe591f6/0iY927OAD4uU/lsm\",\"shard\":\"0iY927OAD4uU\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":109793}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_879b583a0e644a58b62b7e37ebe2a3b0_b8dmtMmmcU2a in 2.485734ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_879b583a0e644a58b62b7e37ebe2a3b0\",\"index\":\"langchain_879b583a0e644a58b62b7e37ebe2a3b0\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_879b583a0e644a58b62b7e37ebe2a3b0/b8dmtMmmcU2a/lsm\",\"shard\":\"b8dmtMmmcU2a\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":86049}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_be0621772dc242e19f5804db2bab9a12_OsuEejcHErWq in 2.112749ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_be0621772dc242e19f5804db2bab9a12\",\"index\":\"langchain_be0621772dc242e19f5804db2bab9a12\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_be0621772dc242e19f5804db2bab9a12/OsuEejcHErWq/lsm\",\"shard\":\"OsuEejcHErWq\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":73691}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_f1903ccca9934092999f9b13ae383d2b_WXzB6bLwg8BL in 1.832378ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_f1903ccca9934092999f9b13ae383d2b\",\"index\":\"langchain_f1903ccca9934092999f9b13ae383d2b\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_f1903ccca9934092999f9b13ae383d2b/WXzB6bLwg8BL/lsm\",\"shard\":\"WXzB6bLwg8BL\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":70705}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_7e6b06461f0c41709a31b462433baa0d_LPIrG0fErBiY in 2.020136ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_7e6b06461f0c41709a31b462433baa0d\",\"index\":\"langchain_7e6b06461f0c41709a31b462433baa0d\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_7e6b06461f0c41709a31b462433baa0d/LPIrG0fErBiY/lsm\",\"shard\":\"LPIrG0fErBiY\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":84373}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_b6d542c2d3b746dfa3e47cd88b6eaf2f_iiiGhZYZiH3U in 1.907595ms\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"lsm_compaction\",\"class\":\"LangChain_b6d542c2d3b746dfa3e47cd88b6eaf2f\",\"index\":\"langchain_b6d542c2d3b746dfa3e47cd88b6eaf2f\",\"level\":\"warning\",\"msg\":\"compaction halted due to shard READONLY status\",\"path\":\"/Users/azizamed/.local/share/weaviate/langchain_b6d542c2d3b746dfa3e47cd88b6eaf2f/iiiGhZYZiH3U/lsm\",\"shard\":\"iiiGhZYZiH3U\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"set_shard_read_only\",\"level\":\"warning\",\"msg\":\"Set READONLY, disk usage currently at 91.87%, threshold set to 90.00%\",\"path\":\"/Users/azizamed/.local/share/weaviate\",\"time\":\"2024-01-20T11:10:30+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:30+03:00\",\"took\":71142}\n",
      "/usr/local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "{\"level\":\"info\",\"msg\":\"Created shard langchain_06cc878a490c476d89ad9d1595e7d504_Y7GML0NkPoVj in 2.55601ms\",\"time\":\"2024-01-20T11:10:31+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-20T11:10:31+03:00\",\"took\":89806}\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "chunks =  data_loader()\n",
    "retriever = create_retriever(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0)\n",
    "\n",
    "# Define prompt template\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use two sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Setup RAG pipeline\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/chat_models/openai.py:458: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/chat_models/openai.py:458: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/chat_models/openai.py:458: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/chat_models/openai.py:458: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/chat_models/openai.py:458: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/chat_models/openai.py:458: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions = [\n",
    "    \"What is the primary business objective of PromptlyTech?\",\n",
    "    \"Name the key services provided by PromptlyTech.\",\n",
    "    \"Explain the importance of Automatic Evaluation Data Generation in PromptlyTech's offerings.\",\n",
    "    \"How does the ELO Rating System work in the context of prompt testing and ranking?\",\n",
    "    \"What are some innovative approaches suggested for prompt evaluation in Task 5?\",\n",
    "    \"How does the user interface contribute to the overall prompt engineering system in Task 5?\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    [\"PromptlyTech is an innovative e-business specializing in providing AI-driven solutions for optimizing the use of Language Models (LLMs) in various industries. The company aims to revolutionize how businesses interact with LLMs, making the technology more accessible, efficient, and effective. By addressing the challenges of prompt engineering, the company plays a pivotal role in enhancing decision-making, operational efficiency, and customer experience across various industries.\"],\n",
    "    [\"PromptlyTech focuses on key services: Automatic Prompt Generation, Automatic Evaluation Data Generation, and Prompt Testing and Ranking.\"],\n",
    "    [\"Automatic Evaluation Data Generation is a crucial service offered by PromptlyTech. This service automates the generation of diverse test cases, ensuring comprehensive coverage and identifying potential issues. By creating a set of test cases that serve as evaluation benchmarks for prompt candidates, PromptlyTech enhances the reliability and performance of LLM applications. This, in turn, saves significant time in the Quality Assurance (QA) process.\"],\n",
    "    [\"The ELO Rating System, commonly used in chess and other competitive games, rates prompts based on their performance in battles. Each prompt candidate is assigned a rating that reflects its success in previous matchups. The system takes into account not just the number of wins but also the strength of the opponents each prompt has defeated. This rating helps in objectively ranking the prompts based on their effectiveness in generating desired outcomes.\"],\n",
    "    [\"Task 5 emphasizes adopting innovative approaches to prompt evaluation, including utilizing Monte Carlo matchmaking and ELO rating systems. Additionally, alternative methods such as TrueSkill Rating System, Glicko Rating System, Bayesian Rating Systems, Pairwise Comparison Methods, Categorical Ranking, Adaptive Ranking Algorithms, and Semantic Similarity Matching are mentioned. These methods provide a dynamic and adaptive framework for evaluating prompts in various contexts.\"],\n",
    "    [\"The user interface plays a crucial role in Task 5 by providing a user-friendly platform for interacting with the prompt engineering system. It allows users to easily input data, receive prompts, and view evaluation results. The design and implementation of the user interface aim to enhance the overall user experience, making it intuitive and efficient for users to engage with the automated prompt generation, evaluation data generation, and prompt testing components.\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "# Inference\n",
    "for query in questions:\n",
    "\n",
    "  answers.append(rag_chain.invoke(query))\n",
    "  contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# To dict\n",
    "data = {\n",
    "    \"question\": questions, # list \n",
    "    \"answer\": answers, # list\n",
    "    \"contexts\": contexts, # list list\n",
    "    \"ground_truths\": ground_truths # list Lists\n",
    "}\n",
    "\n",
    "# Convert dict to dataset\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:09<00:00,  9.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:14<00:00, 14.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                               | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset = dataset, \n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "    ],\n",
    ")\n",
    "\n",
    "df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who founded OpenAI?</td>\n",
       "      <td>OpenAI was founded by Sam Altman, Elon Musk, I...</td>\n",
       "      <td>[OpenAI was initially founded in 2015 by Sam A...</td>\n",
       "      <td>[Sam Altman, Elon Musk, Ilya Sutskever and Gre...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.959185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was the initial goal of OpenAI?</td>\n",
       "      <td>The initial goal of OpenAI was to advance digi...</td>\n",
       "      <td>[OpenAI was initially founded in 2015 by Sam A...</td>\n",
       "      <td>[To advance digital intelligence in a way that...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What did OpenAI release in 2016?</td>\n",
       "      <td>OpenAI released 'OpenAI Gym' in 2016, a toolki...</td>\n",
       "      <td>[The early years of OpenAI were marked with ra...</td>\n",
       "      <td>[OpenAI Gym, a toolkit for developing and comp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.899221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               question  \\\n",
       "0                   Who founded OpenAI?   \n",
       "1  What was the initial goal of OpenAI?   \n",
       "2      What did OpenAI release in 2016?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  OpenAI was founded by Sam Altman, Elon Musk, I...   \n",
       "1  The initial goal of OpenAI was to advance digi...   \n",
       "2  OpenAI released 'OpenAI Gym' in 2016, a toolki...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [OpenAI was initially founded in 2015 by Sam A...   \n",
       "1  [OpenAI was initially founded in 2015 by Sam A...   \n",
       "2  [The early years of OpenAI were marked with ra...   \n",
       "\n",
       "                                       ground_truths  context_precision  \\\n",
       "0  [Sam Altman, Elon Musk, Ilya Sutskever and Gre...                1.0   \n",
       "1  [To advance digital intelligence in a way that...                1.0   \n",
       "2  [OpenAI Gym, a toolkit for developing and comp...                1.0   \n",
       "\n",
       "   context_recall  faithfulness  answer_relevancy  \n",
       "0             1.0           1.0          0.959185  \n",
       "1             1.0           1.0          0.999999  \n",
       "2             1.0           1.0          0.899221  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integration with Retrieval-Augmented Generation Assessment:\n",
    "##### Monte Carlo for Robustness Testing: Use Monte Carlo simulations to test the robustness of the RAG system across a wide range of possible retrieval scenarios. This helps in understanding how different types of retrieved information can impact the quality of the generated content.\n",
    "##### Elo Rating for Continuous Improvement: Utilize the Elo rating system to continuously assess and improve the RAG model. By comparing new outputs with previous ones and adjusting ratings accordingly, the system can learn which types of retrieval-augmented generations work best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f3c0b24c41e80e94b84b01069c679ceb9a0604be81ab76bb66c9ea948f7d76b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
